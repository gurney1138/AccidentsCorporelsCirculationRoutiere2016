{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accidents Corporels de la Circulation Routière 2016\n",
    "## Utilisation de Shapash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "Données: data.gouv.fr\n",
    "\n",
    "https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2019/\n",
    "\n",
    "\n",
    "Shapash: \n",
    "\n",
    "https://pub.towardsai.net/shapash-making-ml-models-understandable-by-everyone-8f96ad469eb3\n",
    "\n",
    "https://github.com/MAIF/shapash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Les packages  \n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "import collections\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "### Les options générales\n",
    "pd.set_option(\"display.max_columns\", 99) # permet de voir toutes les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/11942h/.conda/envs/FBE_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "### Chargement des données\n",
    "\n",
    "#Impossible de charger le fichier caractéristiques avec l'ensemble des colonnes\n",
    "#d1 Caractéristiques de l'accident\n",
    "d1 = pd.read_csv(\"caracteristiques_2016_col_reduit.csv\" #59 432\n",
    "                 ,sep=','\n",
    "                 ,header='infer'\n",
    "                 ,encoding='utf-8')\n",
    "\n",
    "#d2 Lieux de l'accident\n",
    "d2 = pd.read_csv(\"lieux_2016.csv\" #59 432\n",
    "                 ,sep=','\n",
    "                 ,header='infer'\n",
    "                 ,encoding='utf-8')\n",
    "\n",
    "#d3 Véhicules accidentés\n",
    "d3 = pd.read_csv(\"vehicules_2016.csv\" #101 924\n",
    "                 ,sep=','\n",
    "                 ,header='infer'\n",
    "                 ,encoding='utf-8')\n",
    "\n",
    "#d4 Usagers\n",
    "d4 = pd.read_csv(\"usagers_2016.csv\" #133 422\n",
    "                 ,sep=','\n",
    "                 ,header='infer'\n",
    "                 ,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recodages, renommages et constitution de la table de travail\n",
    "\n",
    "d1['heure'] = d1['hrmn'].apply(lambda x: '{0:0>4}'.format(x)).str.slice(stop=2).astype(int) # On ne garde que l'heure de l'accident\n",
    "d1['col'].fillna(6, inplace=True)\n",
    "d1.rename(columns={'lum':'lumiere'}, inplace=True)\n",
    "d1.rename(columns={'agg':'agglomeration'}, inplace=True)\n",
    "d1.rename(columns={'int':'intersection'}, inplace=True)\n",
    "d1.rename(columns={'atm':'condition_atmospherique'}, inplace=True)\n",
    "d1.rename(columns={'col':'collision'}, inplace=True)\n",
    "\n",
    "d2.rename(columns={'nbv':'nombre_voies'}, inplace=True)\n",
    "d2.rename(columns={'catr':'categorie_route'}, inplace=True)\n",
    "d2.rename(columns={'circ':'circulation'}, inplace=True)\n",
    "d2.rename(columns={'prof':'profil'}, inplace=True)\n",
    "d2.rename(columns={'surf':'etat_surface'}, inplace=True)\n",
    "d2.rename(columns={'infra':'infrastructure'}, inplace=True)\n",
    "d2.rename(columns={'infra':'infrastructure'}, inplace=True)\n",
    "d2.rename(columns={'vosp':'voie_reservee'}, inplace=True)\n",
    "d2.rename(columns={'plan':'trace'}, inplace=True)\n",
    "d2['nombre_voies'] = np.where(d2['nombre_voies'] > 8, 8, d2['nombre_voies']) # On limite de nombre de voies à 8 et plus\n",
    "\n",
    "d3.rename(columns={'obs':'obstacle'}, inplace=True)\n",
    "d3['catv'] = np.where(d3['catv'] == 35, 36, d3['catv']) # Regroupement quads\n",
    "d3.rename(columns={'catv':'categorie_veh'}, inplace=True)\n",
    "d3.rename(columns={'obsm':'obstacle_mobile'}, inplace=True)\n",
    "\n",
    "d3b = d3.groupby(['Num_Acc']).size().reset_index(name='nb_veh')\n",
    "d3b.rename(columns={'nb_veh':'nombre_vehicules'}, inplace=True)\n",
    "d3b['nombre_vehicules'] = np.where(d3b['nombre_vehicules'] > 8, 8, d3b['nombre_vehicules']) # On limite à 8 véhicules concernés et plus\n",
    "\n",
    "d4.rename(columns={'grav':'gravite'}, inplace=True)\n",
    "d4.rename(columns={'catu':'usager'}, inplace=True)\n",
    "\n",
    "d4b = d4.groupby(['Num_Acc']).size().reset_index(name='nb_usagers')\n",
    "d4c = d4[(d4.gravite == 2)].groupby(['Num_Acc']).size().reset_index(name='nb_tues')\n",
    "d4b.rename(columns={'nb_usagers':'nombre_usagers'}, inplace=True)\n",
    "d4b['nombre_usagers'] = np.where(d4b['nombre_usagers'] >8, 8, d4b['nombre_usagers']) # On limite à 8 usagers et plus\n",
    "\n",
    "\n",
    "# Regroupements - Table de travail à l'usager\n",
    "d10 = pd.merge(d3, d4, on=['Num_Acc', 'num_veh'], how='inner')\n",
    "dfs = [d10, d1, d2, d3b, d4b, d4c]\n",
    "d11 = reduce(lambda  left,right: pd.merge(left, right, on=['Num_Acc'], how='left'), dfs).fillna(0)\n",
    "\n",
    "# Recodage de la variable endogène\n",
    "y = d4['gravite'] == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dictionnaire\n",
    "ta = {'col': 'lumiere',\n",
    "       'mapping': pd.Series(data=[1, 2, 3, 4, 5, 0],\n",
    "                            index=['Plein jour', 'Crépuscule ou aube', 'Nuit sans éclairage public',\n",
    "                                   'Nuit avec éclairage public non allumé', 'Nuit avec éclairage public allumé',\n",
    "                                   'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tb = {'col': 'agglomeration',\n",
    "       'mapping': pd.Series(data=[1, 2, 0],\n",
    "                            index=['Hors agglomération', 'En agglomératio', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tc = {'col': 'intersection',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 0],\n",
    "                             index=['Hors intersection', 'Intersection en X', 'Intersection en T', 'Intersection en Y',\n",
    "                                   'Intersection à plus de 4 branches', 'Giratoire', 'Place', 'Passage à niveau',\n",
    "                                   'Autre intersection', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "td = {'col': 'condition_atmospherique',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 0],\n",
    "                             index=['Normale', 'Pluie légère', 'Pluie forte', 'Neige - grêle', 'Brouillard - fumée',\n",
    "                                    'Vent fort - tempête', 'Temps éblouissant', 'Temps couvert', 'Autre', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "te = {'col': 'collision',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7,8],\n",
    "                             index=['2 véhicules - frontale', '2 véhicules – arrière', '2 véhicules – coté', '3 véh et + – en chaîne',\n",
    "                                    '3 véh et + - collisions mult', 'Autre collision', 'Sans collision', 'Passage à niveau']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tf = {'col': 'categorie_route',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7, 0],\n",
    "                             index=['Autoroute', 'Route Nationale', 'Route Départementale', 'Voie Communale', 'Hors réseau public',\n",
    "                                    'Parc de stationnement', 'autre', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tg = {'col': 'circulation',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 0],\n",
    "                             index=['A sens unique', 'Bidirectionnelle', 'A chaussées séparées', 'Voies affectation variable',\n",
    "                                    'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "th = {'col': 'profil',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 0],\n",
    "                             index=['Plat', 'Pente', 'Sommet de côte', 'Bas de côte', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "ti = {'col': 'infrastructure',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7, 8, 0],\n",
    "                             index=['Rien', 'Souterrain - tunnel', 'Pont - autopont', 'Bretelle ', 'Voie ferrée', \n",
    "                                    'Carrefour aménagé', 'Zone piétonne', 'Zone de péage', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tj = {'col': 'voie_reservee',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 0],\n",
    "                             index=['Piste cyclable', 'Banque cyclable', 'Voie réservée', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tk = {'col': 'trace',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 0],\n",
    "                             index=['Partie rectiligne', 'En courbe à gauche', 'En courbe à droite', 'En S', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tl = {'col': 'obstacle',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10 , 11, 12, 13, 14, 15, 16, 0],\n",
    "                             index=['Véhicule en stationnement', 'Arbre', 'Glissière métallique', 'Glissière béton', 'Autre glissière'\n",
    "                                    , 'Bâtiment, mur, pile', 'Support de signalisation', 'Poteau', 'Mobilier urbain', 'Parapet'\n",
    "                                    , 'Ilot, refuge, borne haute', 'Bordure de trottoir', 'Fossé, talus, paroi rocheuse'\n",
    "                                    , 'Autre obstacle fixe sur chaussée', 'Autre obstacle fixe sur trottoir ou accotement'\n",
    "                                    , 'Sortie de chaussée sans obstacle', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tm = {'col': 'obstacle_mobile',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 0],\n",
    "                             index=['Piéton', 'Véhicule', 'Véhicule sur rail', 'Animal domestique' ,'Animal sauvage', 'Autre'\n",
    "                                    , 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "tn = {'col': 'choc',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 0],\n",
    "                             index=['Avant', 'Avant droit', 'Avant gauche', 'Arrière', 'Arrière droit', 'Arrière gauche'\n",
    "                                    , 'Côté droit', 'Côté gauche', 'Chocs multiples (tonneaux)', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "to = {'col': 'usager',\n",
    "        'mapping': pd.Series(data=[1, 2, 3, 4, 0],\n",
    "                             index=['Conducteur', 'Passagé', 'Piéton', 'Piéton en roller ou trotinette', 'Non renseigné']),\n",
    "       'data_type': 'object'}\n",
    "\n",
    "# Liste des transformations\n",
    "encoder = [ta, tb, tc, td, te, tf, tg, th, ti, tj, tk, tl, tm, tn, to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Xtrain & Xtest\n",
    "X = d11[['mois', 'jour', 'heure', 'nombre_voies', 'nombre_vehicules', 'nombre_usagers'\n",
    "         ,'lumiere','agglomeration', 'intersection', 'condition_atmospherique', 'collision'\n",
    "         , 'categorie_route', 'circulation', 'profil', 'infrastructure', 'voie_reservee'\n",
    "         , 'trace',  'obstacle', 'obstacle_mobile', 'choc', 'usager']]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: subsamble\n",
      "[[24142  8316]\n",
      " [  178   720]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.7453531598513011)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modélisation\n",
    "\n",
    "model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                               subsamble=0.7,\n",
    "                               reg_lambda=2,\n",
    "                               reg_alpha=0,\n",
    "                               objective='binary',\n",
    "                               num_leaves=8,\n",
    "                               n_estimators=600,\n",
    "                               learning_rate=0.03,\n",
    "                               is_unbalance=True,\n",
    "                               colsample_bytree=0.7,\n",
    "                               boosting_type='gbdt',\n",
    "                               random_state=314, silent=True, metric='None', n_jobs=4)\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "ypred = model.predict(Xtest)\n",
    "\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "print(cm), np.trace(cm) / np.sum(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: Shap TreeExplainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/11942h/.conda/envs/FBE_py38/lib/python3.8/site-packages/shap/explainers/_tree.py:300: UserWarning:\n",
      "\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Shapash\n",
    "\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "\n",
    "y_pred = pd.DataFrame(pd.Series(ypred).astype(int), index=Xtest.index, columns=['ypred']).fillna(0)\n",
    "\n",
    "xpl = SmartExplainer()\n",
    "\n",
    "xpl.compile(\n",
    "    x = Xtest,\n",
    "    preprocessing = encoder,\n",
    "    model = model,\n",
    "    y_pred = y_pred.ypred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:172.16.87.97 - - [14/Apr/2021 12:02:48] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:172.16.87.97 - - [14/Apr/2021 12:02:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = xpl.run_app(port=8051)\n",
    "\n",
    "# Après exécution, à titre d'exemple sur le serveur utilisé dans cas: INFO:root:Your Shapash application run on http://slhdg001:8051/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FBE_py38",
   "language": "python",
   "name": "fbe_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
